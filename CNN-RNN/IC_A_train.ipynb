{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIqJsO9Rh-TE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import csv\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8_o9onOiH43",
        "outputId": "2e45b6f1-9ffa-49cc-cafb-0ef3ad40e541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yah-ZIjIqpH2"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embed_size = embed_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.lstm_cell = nn.LSTMCell(embed_size, hidden_size,num_layers)\n",
        "        self.fc_out = nn.Linear(in_features=self.hidden_size, out_features=self.vocab_size)\n",
        "        self.embed = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=self.embed_size)\n",
        "        self.dropout=nn.Dropout(0.5)\n",
        "        # activations\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        batch_size = features.size(0)\n",
        "        # init the hidden and cell states to zeros\n",
        "        hidden_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
        "        cell_state = torch.zeros((batch_size, self.hidden_size)).cuda()\n",
        "\n",
        "        # define the output tensor placeholder\n",
        "        outputs = torch.empty((batch_size, captions.shape[1], self.vocab_size)).cuda()\n",
        "\n",
        "        # embed the captions\n",
        "        captions_embed = self.dropout(self.embed(captions)).cuda()\n",
        "        # print(\"Captions_embed size :- \",captions_embed.shape)\n",
        "        # pass the caption word by word\n",
        "        for t in range(captions.size(1)):\n",
        "\n",
        "            # for the first time step the input is the feature vector\n",
        "            if t == 0:\n",
        "                hidden_state, cell_state = self.lstm_cell(features, (hidden_state, cell_state))\n",
        "\n",
        "            # for the 2nd+ time step, using teacher forcer\n",
        "            else:\n",
        "                # print(\"hidden_state size :- \",captions_embed[:, t, :].shape)\n",
        "                hidden_state, cell_state = self.lstm_cell(captions_embed[:, t, :], (hidden_state, cell_state))\n",
        "\n",
        "            # output of the attention mechanism\n",
        "            out = self.fc_out(hidden_state).cuda()\n",
        "\n",
        "            # build the output tensor\n",
        "            outputs[:, t, :] = out.cuda()\n",
        "\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class JsonData(Dataset):\n",
        "    def __init__(self,vocab_path, json_path):\n",
        "      with open(vocab_path, 'r') as json_file:\n",
        "        self.vocabulary = json.load(json_file)\n",
        "      with open(json_path, 'r') as json_file1:\n",
        "        self.data = json.load(json_file1)\n",
        "    def __len__(self):\n",
        "      return len(self.data.keys())\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "      feature = torch.tensor(self.data[str(idx)]['feature'])\n",
        "      caption = torch.tensor(self.data[str(idx)]['caption'])\n",
        "      return {\n",
        "            'feature':feature,\n",
        "            'caption':caption\n",
        "        }\n",
        "def custom_collate(batch):   #custom collate for converting batch 1X5X2024 to 5X2024\n",
        "  # print(batch)\n",
        "  return batch[0]\n",
        "\n",
        "\n",
        "json_data_path=\"/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/train_data.json\"\n",
        "vocab_path=r\"/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/vocabulary.json\"\n",
        "train_data=JsonData(vocab_path,json_data_path)\n",
        "train_dataloader = DataLoader(train_data, batch_size = 1, shuffle = False,collate_fn=custom_collate)\n",
        "# collate_fn=custom_collate"
      ],
      "metadata": {
        "id": "Uguae9QRjzUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data.__getitem__(0)\n",
        "# train_data.data.keys()\n",
        "# len(data['feature'][0])\n",
        "# feature = torch.tensor(data['feature'])\n",
        "# caption = torch.tensor(data['caption'])"
      ],
      "metadata": {
        "id": "8wADQPCXoCu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_size=1024\n",
        "hidden_size=feature_size\n",
        "learning_rate=3e-4\n",
        "vocab_size=len(train_data.vocabulary.keys())\n",
        "vocab_size\n",
        "num_epochs=1"
      ],
      "metadata": {
        "id": "bl0kARktiLni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# load_model = False\n",
        "# save_model = True\n",
        "device\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lsdhveOzAxl",
        "outputId": "f11c80fb-e531-468c-b6a2-b16611ae63df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=DecoderRNN(feature_size,feature_size,vocab_size).cuda()\n",
        "optimizer=optim.Adam(model.parameters(),lr=learning_rate)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "# losses = torch.tensor([], device='cuda')\n",
        "losses=list()\n",
        "model.train()\n",
        "# model=model.to(device)\n",
        "for i in model.parameters():\n",
        "  print(i.is_cuda)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AnBJpUGipaC",
        "outputId": "76b1f137-40e8-4578-a8b9-07a0d81b5907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epoch=4\n",
        "for batch in train_dataloader:\n",
        "    # print(\"shapes :- \",batch['feature'].shape,\" \",batch['caption'].shape)\n",
        "    features = batch['feature'].cuda()\n",
        "    # print(features.is_cuda)\n",
        "    captions = batch['caption'].cuda()\n",
        "    # print(captions.is_cuda)\n",
        "    output = model(features,captions)\n",
        "    loss = criterion(output.view(-1, len(train_data.vocabulary)), captions.contiguous().view(-1))\n",
        "    losses.append(loss)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/trained_model.pth')"
      ],
      "metadata": {
        "id": "HlsPy80g4y0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses[5700:]"
      ],
      "metadata": {
        "id": "ebIVIerei89l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c9e430-51be-4435-ec36-83a1afcf8fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.6165, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.4265, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.3661, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.2850, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.4195, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.3177, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.6445, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.0698, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.4014, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(2.0305, device='cuda:0', grad_fn=<NllLossBackward0>),\n",
              " tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # for tensorboard\n",
        "# writer = SummaryWriter(\"runs/flickr\")\n",
        "# step = 0\n",
        "# # initialize model, loss etc\n",
        "# model = DecoderRNN(feature_size,feature_size,len(train_data.vocabulary)).to (device)\n",
        "# criterion = nn.CrossEntropyLoss (ignore_index=dataset.vocab.stoi[\"<PAD>\"])\n",
        "# optimizer = optim. Adam (model.parameters(), lr=learning_rate)\n",
        "# if load_model:\n",
        "#   step =load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)\n",
        "# model.train()\n",
        "# for epoch in range(num_epochs):\n",
        "#   if save_model:\n",
        "#     checkpoint = {\n",
        "#       \"state_dict\": model.state_dict(),\n",
        "#       \"optimizer\": optimizer.state_dict(),\n",
        "#       \"step\": step,\n",
        "#     }\n",
        "#     save_checkpoint(checkpoint)\n",
        "  # for idx, (imgs, captions) in enumerate (train_loader):\n",
        "  #   imgs=imgs.to (device)\n",
        "  #   captions=captions.to (device)\n",
        "  #   outputs = model(imgs, captions [:-1])\n",
        "  #   loss = criterion (outputs.reshape(-1, outputs.shape[2]), caption.reshape(-1))\n",
        "  #   writer.add_scalar(\"Training loss\", loss.item(), global_step=step)\n",
        "  #   step += 1\n",
        "  #   optimizer.zero_grad()\n",
        "  #   loss.backward (loss)\n",
        "  #   optimizer.step()"
      ],
      "metadata": {
        "id": "dUuysErB2Inf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IVMJUghnGwUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}