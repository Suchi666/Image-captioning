{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4xX9TuQrglO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import csv\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngmWcokLO4k9",
        "outputId": "c21de2fc-7aa1-4bdd-ed98-b35b1919e837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from model_A import ImageCaptioner,EncoderCNN, DecoderRNN\n",
        "import os\n",
        "import csv"
      ],
      "metadata": {
        "id": "GIDpER0ocBR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zup5cpd0QVSj"
      },
      "outputs": [],
      "source": [
        "feature_size=1024\n",
        "hidden_size=feature_size\n",
        "learning_rate=3e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0feXoLiPUmcy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFsqNNLrVKws"
      },
      "outputs": [],
      "source": [
        "class TrainData(Dataset):\n",
        "    def __init__(self, img_path, caption_path):\n",
        "        # self.img_folder=image_path\n",
        "        file_list = os.listdir(img_path)\n",
        "        file_list = sorted(file_list, key=lambda x: int(x[6:-4]))\n",
        "        self.image_path = []\n",
        "        for file in file_list:\n",
        "          path=os.path.join(img_path,file)\n",
        "          self.image_path.append(path)\n",
        "\n",
        "        self.captions=[]\n",
        "        with open(caption_path, mode='r') as file:\n",
        "          reader = csv.reader(file)\n",
        "          for row in reader:\n",
        "            self.captions.append(row)\n",
        "        self.captions=self.captions[1:]\n",
        "        self.captions=[arr[2] for arr in self.captions]\n",
        "        # self.captions=self.captions[:10]\n",
        "\n",
        "        self.processor = transforms.Compose([\n",
        "          transforms.Resize((224, 224)),  # Resize image to match model input size\n",
        "          transforms.ToTensor(),           # Convert image to tensor\n",
        "          transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize image\n",
        "        ])\n",
        "\n",
        "        words = [word for string in self.captions for word in string.split()]\n",
        "        unique_words = list(set(words))\n",
        "        unique_words.sort()\n",
        "        unique_words.append('<START>')\n",
        "        unique_words.append('<EOS>')\n",
        "        self.vocabulary=unique_words.copy()\n",
        "        self.vocabulary={i:word for i,word in enumerate(self.vocabulary)}\n",
        "        with open('/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/vocabulary.json', 'w') as json_file:\n",
        "          json.dump(self.vocabulary, json_file)\n",
        "        self.encoder=EncoderCNN()\n",
        "        # self.vocabulary\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.captions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name=self.image_path[idx]\n",
        "        input_image = Image.open(img_name)\n",
        "        if input_image.mode != 'RGB':\n",
        "          input_image = input_image.convert('RGB')\n",
        "        input_tensor = self.processor(input_image)\n",
        "        input_batch = input_tensor.unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "          output = self.encoder.forward(input_batch)\n",
        "\n",
        "        captions=self.captions[idx].split()\n",
        "\n",
        "        indexes={word:i for i,word in self.vocabulary.items()}\n",
        "        # print(indexes)\n",
        "        start_token=indexes['<START>']\n",
        "        caption_idx=[]\n",
        "        caption_idx.append(start_token)\n",
        "        word_idx_map=[indexes[word] for word in captions]\n",
        "        caption_idx=caption_idx+word_idx_map\n",
        "        caption_idx.append(indexes['<EOS>'])\n",
        "        token = torch.tensor(caption_idx)\n",
        "        token = token.unsqueeze(0)\n",
        "\n",
        "        return {\n",
        "            'feature':output,\n",
        "            'caption':token\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "caption_path=\"/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/train.csv\"\n",
        "img_path=r\"/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/train\"\n",
        "train_data=TrainData(img_path,caption_path)\n",
        "voc=train_data.vocabulary\n",
        "data=train_data.__getitem__(87)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdM2TRiYRvPy",
        "outputId": "9d9f9735-8bb8-4edd-b5ca-5e1228859cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
            "100%|██████████| 30.8M/30.8M [00:00<00:00, 138MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dInsJFyPMTOa"
      },
      "outputs": [],
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size = 1, shuffle = False)\n",
        "data_dict={}\n",
        "j=0\n",
        "for i,batch in enumerate(train_dataloader):\n",
        "  print(i ,\"  shapes :- \",batch['feature'][0].shape,\" \",batch['caption'][0].shape)\n",
        "  output_list = batch['feature'][0].tolist()\n",
        "  token_list = batch['caption'][0].tolist()\n",
        "  # Create a dictionary\n",
        "  data = {\n",
        "    'feature': output_list,\n",
        "    'caption': token_list\n",
        "  }\n",
        "  data_dict[i]=data\n",
        "  # Save the dictionary to a JSON file\n",
        "  if i!=0 and i%1000==0:\n",
        "    j=j+1\n",
        "    with open(f'/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/train_data_{i/1000}.json', 'w') as json_file:\n",
        "      json.dump(data_dict, json_file)\n",
        "    data_dict={}\n",
        "with open(f'/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/train_data_{j+1}.json', 'w') as json_file:\n",
        "  json.dump(data_dict, json_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "merged_data = {}\n",
        "# Loop through each JSON file\n",
        "for i in range(1, 7):\n",
        "    with open(f'/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/train_data_{i}.json', 'r') as file:\n",
        "        data = json.load(file)  # Load JSON content into a dictionary\n",
        "        merged_data.update(data)  # Merge the dictionaries\n",
        "print(len(merged_data.keys()))\n",
        "# Write the merged data into a new JSON file\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Data/IC_dataset/train_data.json', 'w') as outfile:\n",
        "    json.dump(merged_data, outfile, indent=4)  # Write merged data to the file with indentation"
      ],
      "metadata": {
        "id": "Oz7euEvXAcNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}